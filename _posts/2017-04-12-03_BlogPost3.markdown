---
layout: default
title:  "Verifying News: Blog Post 3"
date:   2017-04-12 19:11:00
categories: main
---
# Verifying News: Blog Post 3

## What's New?
Since our midterm blog post, we've done some exciting new work with our machine learning processes. Previously we had fully implemented SVM machine learning classification to work with on our training set, and this week we have new progress implementing some clustering of news articles. What our goal is here is to be able to identify and group articles with similar MEANING from the features provided in the Webhose data and our own web scraping. Trying to capture actual meaning in computing language is very difficult, and something we will describe below, and finally talk about our thoughts going forwards.

## Clustering
First we researched different papers and read many blogposts regarding clustering articles based on meaning, or containing similar events. One blog post we found that stood out in particular is ![here](blog.chartbeat.com/2015/10/22/identifying-and-clustering-news-events-by-content/). 

The general approach we implemented, with suggestion from the above blog post was to:
1. Separate the article text from each article
2. Use Named Entity Recognition (we used Stanford's NLP NER) to extract significatn entities
3. Vectorize each article's text using the TF-IDF measure
4. Run clustering on these vectors recognizing each article

Here we make the following assumptions:
- We can typically identify a specific event/piece of information by looking at the named/significant entities in a body of an article. In particular we take tagged Location, Person, Organization, Money, Percent, Date, Time from Stanford NLP. 
- TF-IDF vecorization is a good measure of phrase significance in a particular article, that we can then translate into identifying the "meaning" of a particular article.
- More...

## Coding
We implement all this in python, and in particular we used Jupyter Notebook as an interactive and easy way to explore our data.

## Exploring the clustering
Here are the counts per cluster we found with n=20 clusters. 
![News Verification Visualization 1]({{ site.url }}/verifynews/assets/cluster-counts.png)

From comparing items of similar clusters, unfortunately the information between items was not very similar in many cases. For example, we got a webpage from bloomberg describing subscribing to an evening digest grouped with Trump meeting Xi Jin Ping.

## Challenges and moving forwards
With this current K-Means clustering, we manually set and test K. The ultimate goal is to use a hierarchical agglomerate clustering with a posterior so that we can compute the probability of a new item being a part of any existing cluster, and the probability for the article being in a new created cluster, with the number of clusters being algorithmically determined. 

More importantly though, from exploring our current clustering, we need to explore new distance measures and vectorization to capture meaning. Right now, with tf-idf using bigrams as well, the dimensionality seems possibility too high to provide meaningful data. We potentially need to reconsider what method of vectorization we use (if any) and also what distance measure would be appropriate to compare "meaning" between articles.

At the same time, we will continue to improve experience in our web tool/application. We are exploring doing live visualization of articles that are being published, and we can cluster and group those items as a part of our final piece.
